{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(NLP)Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAZLGqQQZ8F62vKJp20NrB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moey920/NLP/blob/master/(NLP)Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caWuaAnmh1ri",
        "colab_type": "code",
        "outputId": "d47e78b4-4abc-474b-cce8-d59a71f876aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        "  code by Tae Hwan Jung(Jeff Jung) @graykode, Derek Miller @dmmiller612\n",
        "  Reference : https://github.com/jadore801120/attention-is-all-you-need-pytorch\n",
        "              https://github.com/JayParks/transformer\n",
        "'''\n",
        "'''\n",
        "  code by Tae Hwan Jung(Jeff Jung) @graykode, Derek Miller @dmmiller612\n",
        "  Reference : https://github.com/jadore801120/attention-is-all-you-need-pytorch\n",
        "              https://github.com/JayParks/transformer\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "# S: Symbol that shows starting of decoding input\n",
        "# E: Symbol that shows starting of decoding output\n",
        "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
        "sentences = ['부분교회 영수증 선물교환증에 지침 P', 'S 부분교환 영수증 선물교환증을 지참', '부분교환 영수증 선물교환증을 지참 E']\n",
        "# 데이터셋을 어떻게 읽어와서 이와 같은 형식으로 저장해야할까요?\n",
        "# Transformer Parameters\n",
        "# Padding Should be Zero index\n",
        "src_vocab = {'P' : 0, '부분교회' : 1, '영수증' : 2, '/' : 3, '선물교환증에' : 4, '지침' : 5}\n",
        "src_vocab_size = len(src_vocab)\n",
        "\n",
        "tgt_vocab = {'P' : 0, '부분교환' : 1, '영수증' : 2, '/' : 3, '선물교환증을' : 4, '지참' : 5, 'S' : 6, 'E' : 7}\n",
        "number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
        "tgt_vocab_size = len(tgt_vocab)\n",
        "\n",
        "src_len = 5\n",
        "tgt_len = 5\n",
        "\n",
        "d_model = 512  # Embedding Size\n",
        "d_ff = 2048 # FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_layers = 6  # number of Encoder of Decoder Layer\n",
        "n_heads = 8  # number of heads in Multi-Head Attention\n",
        "\n",
        "def make_batch(sentences):\n",
        "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
        "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
        "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
        "    return Variable(torch.LongTensor(input_batch)), Variable(torch.LongTensor(output_batch)), Variable(torch.LongTensor(target_batch))\n",
        "\n",
        "def get_sinusoid_encoding_table(n_position, d_model):\n",
        "    def cal_angle(position, hid_idx):\n",
        "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "    return torch.FloatTensor(sinusoid_table)\n",
        "\n",
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "    # print(seq_q)\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
        "\n",
        "def get_attn_subsequent_mask(seq):\n",
        "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
        "    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\n",
        "    return subsequent_mask\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "        output = nn.Linear(n_heads * d_v, d_model)(context)\n",
        "        return nn.LayerNorm(d_model)(output + residual), attn # output: [batch_size x len_q x d_model]\n",
        "\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        residual = inputs # inputs : [batch_size, len_q, d_model]\n",
        "        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        return nn.LayerNorm(d_model)(output + residual)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = PoswiseFeedForwardNet()\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.dec_self_attn = MultiHeadAttention()\n",
        "        self.dec_enc_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = PoswiseFeedForwardNet()\n",
        "\n",
        "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
        "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
        "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "        dec_outputs = self.pos_ffn(dec_outputs)\n",
        "        return dec_outputs, dec_self_attn, dec_enc_attn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(src_len+1, d_model),freeze=True)\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, enc_inputs): # enc_inputs : [batch_size x source_len]\n",
        "        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(torch.LongTensor([[1,2,3,4,0]]))\n",
        "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n",
        "        enc_self_attns = []\n",
        "        for layer in self.layers:\n",
        "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
        "            enc_self_attns.append(enc_self_attn)\n",
        "        return enc_outputs, enc_self_attns\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(tgt_len+1, d_model),freeze=True)\n",
        "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs): # dec_inputs : [batch_size x target_len]\n",
        "        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(torch.LongTensor([[5,1,2,3,4]]))\n",
        "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)\n",
        "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)\n",
        "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
        "\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n",
        "\n",
        "        dec_self_attns, dec_enc_attns = [], []\n",
        "        for layer in self.layers:\n",
        "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "            dec_self_attns.append(dec_self_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "        return dec_outputs, dec_self_attns, dec_enc_attns\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False)\n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
        "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
        "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns\n",
        "\n",
        "def greedy_decoder(model, enc_input, start_symbol):\n",
        "    \"\"\"\n",
        "    For simplicity, a Greedy Decoder is Beam search when K=1. This is necessary for inference as we don't know the\n",
        "    target sequence input. Therefore we try to generate the target input word by word, then feed it into the transformer.\n",
        "    Starting Reference: http://nlp.seas.harvard.edu/2018/04/03/attention.html#greedy-decoding\n",
        "    :param model: Transformer Model\n",
        "    :param enc_input: The encoder input\n",
        "    :param start_symbol: The start symbol. In this example it is 'S' which corresponds to index 4\n",
        "    :return: The target input\n",
        "    \"\"\"\n",
        "    enc_outputs, enc_self_attns = model.encoder(enc_input)\n",
        "    dec_input = torch.zeros(1, 5).type_as(enc_input.data)\n",
        "    next_symbol = start_symbol\n",
        "    for i in range(0, 5):\n",
        "        dec_input[0][i] = next_symbol\n",
        "        dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)\n",
        "        projected = model.projection(dec_outputs)\n",
        "        prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]\n",
        "        next_word = prob.data[i]\n",
        "        next_symbol = next_word.item()\n",
        "    return dec_input\n",
        "\n",
        "def showgraph(attn):\n",
        "    attn = attn[-1].squeeze(0)[0]\n",
        "    attn = attn.squeeze(0).data.numpy()\n",
        "    fig = plt.figure(figsize=(n_heads, n_heads)) # [n_heads, n_heads]\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attn, cmap='viridis')\n",
        "    ax.set_xticklabels(['']+sentences[0].split(), fontdict={'fontsize': 14}, rotation=90)\n",
        "    ax.set_yticklabels(['']+sentences[2].split(), fontdict={'fontsize': 14})\n",
        "    plt.show()\n",
        "\n",
        "model = Transformer()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "    optimizer.zero_grad()\n",
        "    enc_inputs, dec_inputs, target_batch = make_batch(sentences)\n",
        "    outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
        "    loss = criterion(outputs, target_batch.contiguous().view(-1))\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Test\n",
        "greedy_dec_input = greedy_decoder(model, enc_inputs, start_symbol=tgt_vocab[\"S\"])\n",
        "predict, _, _, _ = model(enc_inputs, greedy_dec_input)\n",
        "predict = predict.data.max(1, keepdim=True)[1]\n",
        "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
        "\n",
        "print('first head of last state enc_self_attns')\n",
        "showgraph(enc_self_attns)\n",
        "\n",
        "print('first head of last state dec_self_attns')\n",
        "showgraph(dec_self_attns)\n",
        "\n",
        "print('first head of last state dec_enc_attns')\n",
        "showgraph(dec_enc_attns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 2.082016\n",
            "Epoch: 0002 cost = 0.794080\n",
            "Epoch: 0003 cost = 0.225716\n",
            "Epoch: 0004 cost = 0.048234\n",
            "Epoch: 0005 cost = 0.058347\n",
            "Epoch: 0006 cost = 0.031972\n",
            "Epoch: 0007 cost = 0.006240\n",
            "Epoch: 0008 cost = 0.004083\n",
            "Epoch: 0009 cost = 0.113057\n",
            "Epoch: 0010 cost = 0.000838\n",
            "Epoch: 0011 cost = 0.005879\n",
            "Epoch: 0012 cost = 0.045267\n",
            "Epoch: 0013 cost = 0.001472\n",
            "Epoch: 0014 cost = 0.004881\n",
            "Epoch: 0015 cost = 0.010316\n",
            "Epoch: 0016 cost = 0.000807\n",
            "Epoch: 0017 cost = 0.000493\n",
            "Epoch: 0018 cost = 0.000635\n",
            "Epoch: 0019 cost = 0.000272\n",
            "Epoch: 0020 cost = 0.000248\n",
            "부분교회 영수증 선물교환증에 지침 P -> ['부분교환', '영수증', '선물교환증을', '지참', 'E']\n",
            "first head of last state enc_self_attns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48512 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 48516 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54924 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50689 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49688 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51613 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49440 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 47932 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54872 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 50640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52840 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51012 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 52280 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48512 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 48516 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54924 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50689 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49688 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51613 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49440 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 47932 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54872 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 50640 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51648 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52840 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51012 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 52280 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "first head of last state dec_self_attns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "first head of last state dec_enc_attns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}