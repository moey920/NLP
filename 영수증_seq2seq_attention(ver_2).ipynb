{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영수증 seq2seq_attention(ver.2)",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nfCVgvWRypOCArD2LBGmenOWY_tBRZo7",
      "authorship_tag": "ABX9TyOS9TbzYu9FjRj2hsI3lq2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moey920/NLP/blob/master/%EC%98%81%EC%88%98%EC%A6%9D_seq2seq_attention(ver_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcvXERxeEqfu",
        "colab_type": "code",
        "outputId": "bdad9352-ded0-4bce-f35a-f72f16c1b3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import layers, models\n",
        "from keras import datasets \n",
        "from keras import backend as K \n",
        "from keras.utils import plot_model \n",
        "import matplotlib \n",
        "from matplotlib import ticker \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "#from IPython.display import Image, display \n",
        "'''\n",
        "import tensorflow.backend as tf\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "from keras.backend import set_session\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "\n",
        "config_proto = tf.ConfigProto()\n",
        "off = rewriter_config_pb2.RewriterConfig.OFF\n",
        "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
        "session = tf.Session(config=config_proto)\n",
        "set_session(session)\n",
        "'''\n",
        "\n",
        "# 학습 정보 \n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "latent_dim = 1024\n",
        "num_samples = 10000\n",
        "data_path = '/content/drive/My Drive/캐시카우_노하람인턴_공유폴더/seq2seq/임시/seq2seq_dataset_No_int.txt' #제작한 데이터 경로를 설정해주세요, 텍스트 파일이 UTF-8로 인코딩 되어있지 않으면 오류가 발생합니다.\n",
        "\n",
        "# 문장 벡터화 \n",
        "input_texts = [] \n",
        "target_texts = [] \n",
        "input_characters = set() \n",
        "target_characters = set() \n",
        "\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:       # data_path를 읽기모드로, utf-8로 인코딩하여 f라는 이름으로 로드한다\n",
        "    lines = f.read().split('\\n')                        # f를 \\n을 기준으로 나누어 한 줄씩 읽어 lines 변수에 저장한다.\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:  # line을 lines까지, 처음부터 lines의 개수\n",
        "                                                        # 훈련 샘플의 개수(10000)개와 실제 로드한 데이터의 개수(len(lines)-1)을 비교하여 최고값을 리턴하고, 처음부터 최소값까지 반복한다.\n",
        "                                                        # 내장함수 min() : 반복가능한 객체의 가장 작은 요소 값을 리턴\n",
        "    input_text, target_text, _ = line.split('\\t')       # input_text(인풋), target_text(아웃풋), _(인덱스)는 한 문장으로 구성되어 있어 각각의 요소를 \\t(TAB)으로 구분한다.\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.    \"\\t\"문자를 시작 문자로, \"\\n\"문자를 종료 문자로 사용.\n",
        "    target_text = '\\t' + target_text + '\\n'             # targer_text는 앞에 '\\t', 뒤에 '\\n'을 붙인다.\n",
        "    input_texts.append(input_text)                      # input_texts 라는 빈 리스트에 input_text를 하나씩 집어넣는다. \n",
        "    target_texts.append(target_text)                    # target_texts 라는 빈 리스트에 target_text를 하나씩 집어넣는다. \n",
        "    for char in input_text:                             # char(character) 변수를 input_text의 처음부터 끝까지\n",
        "        if char not in input_characters:                # 만약 char가 input_characters(집합)에 없다면  \n",
        "            input_characters.add(char)                  # 집합은 문자열을 문자단위로 나누어 원소로 가지고, 중복을 제거한다. 따라서 문장이였던 char에서 중복을 제거한 문자들이 input_characters(집합)에 추가된다.\n",
        "    for char in target_text:                            # char(character) 변수를 input_text의 처음부터 끝까지\n",
        "        if char not in target_characters:               # 만약 char가 input_characters(집합)에 없다면  \n",
        "            target_characters.add(char)                 # 집합에 char변수를 추가한다.\n",
        "\n",
        "# 학습 데이터 개수 \n",
        "num_samples = len(input_texts) \n",
        "input_characters = sorted(list(input_characters)) \n",
        "target_characters = sorted(list(target_characters)) \n",
        "num_encoder_tokens = len(input_characters) \n",
        "num_decoder_tokens = len(target_characters) \n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts]) \n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts]) \n",
        "print('Number of samples:', num_samples) \n",
        "print('Number of unique input tokens:', num_encoder_tokens) \n",
        "print('Number of unique output tokens:', num_decoder_tokens) \n",
        "print('Max sequence length for inputs:', max_encoder_seq_length) \n",
        "print('Max sequence length for outputs:', max_decoder_seq_length) \n",
        "\n",
        "# 문자 -> 숫자 변환용 사전 \n",
        "input_token_index = dict( [(char, i) for i, char in enumerate(input_characters)]) \n",
        "target_token_index = dict( [(char, i) for i, char in enumerate(target_characters)]) \n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열 \n",
        "encoder_input_data = np.zeros( (num_samples, max_encoder_seq_length, num_encoder_tokens), dtype='float32') \n",
        "decoder_input_data = np.zeros( (num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32') \n",
        "decoder_target_data = np.zeros( (num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32') \n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬 \n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)): \n",
        "    for t, char in enumerate(input_text): \n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1. \n",
        "    for t, char in enumerate(target_text): \n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0 :\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1. \n",
        "            \n",
        "# 숫자 -> 문자 변환용 사전 \n",
        "reverse_input_char_index = dict( (i, char) for char, i in input_token_index.items()) \n",
        "reverse_target_char_index = dict( (i, char) for char, i in target_token_index.items()) \n",
        "\n",
        "def RepeatVectorLayer(rep, axis): \n",
        "    return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis), \n",
        "                         lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n",
        "    \n",
        " # 인코더 생성\n",
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True) \n",
        "encoder_outputs, state_h = encoder(encoder_inputs) \n",
        " \n",
        " # 디코더 생성. \n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens)) \n",
        "decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h) \n",
        " \n",
        " # 어텐션 매커니즘. \n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2) \n",
        "repeat_d = repeat_d_layer(decoder_outputs) \n",
        " \n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) \n",
        "repeat_e = repeat_e_layer(encoder_outputs) \n",
        " \n",
        "concat_for_score_layer = layers.Concatenate(axis=-1) \n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e]) \n",
        " \n",
        "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh') \n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer) \n",
        "dense1_score = dense1_score_layer(concat_for_score) \n",
        "dense2_t_score_layer = layers.Dense(1) \n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer) \n",
        "dense2_score = dense2_score_layer(dense1_score) \n",
        "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score) \n",
        " \n",
        "softmax_score_layer = layers.Softmax(axis=-1) \n",
        "softmax_score = softmax_score_layer(dense2_score) \n",
        " \n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2) \n",
        "repeat_score = repeat_score_layer(softmax_score) \n",
        " \n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs) \n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) \n",
        "repeat_e = repeat_e_layer(permute_e) \n",
        " \n",
        "attended_mat_layer = layers.Multiply() \n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e]) \n",
        " \n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1), \n",
        "                              lambda x: tuple(x[:-1])) \n",
        "context = context_layer(attended_mat) \n",
        " \n",
        "concat_context_layer = layers.Concatenate(axis=-1) \n",
        "concat_context = concat_context_layer([context, decoder_outputs]) \n",
        "\n",
        "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh') \n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer) \n",
        "attention_output = attention_output_layer(concat_context) \n",
        "\n",
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax') \n",
        "decoder_outputs = decoder_dense(attention_output) \n",
        "\n",
        "# 모델 생성 \n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "\n",
        "# 콜백함수 정의\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=2, mode='min') # 조기종료 콜백함수 정의\n",
        "\n",
        "choice = input(\"Load weights?\") \n",
        "if choice == 'y' or choice == 'Y': \n",
        "   model.load_weights('att_seq2seq_weights.h5') \n",
        "   \n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc']) \n",
        "model.summary() \n",
        "plot_model(model, show_shapes=True, to_file='model.png') \n",
        "display(Image(filename='model.png')) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 4967\n",
            "Number of unique input tokens: 856\n",
            "Number of unique output tokens: 810\n",
            "Max sequence length for inputs: 79\n",
            "Max sequence length for outputs: 72\n",
            "Load weights?y\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 79, 856)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 72, 810)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_3 (GRU)                     [(None, 79, 1024), ( 5778432     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_4 (GRU)                     [(None, 72, 1024), ( 5637120     input_4[0][0]                    \n",
            "                                                                 gru_3[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 72, 79, 1024) 0           gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 72, 79, 1024) 0           gru_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 72, 79, 2048) 0           lambda_6[0][0]                   \n",
            "                                                                 lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 72, 79, 512)  1049088     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 72, 79, 1)    513         time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 72, 79)       0           time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "softmax_2 (Softmax)             (None, 72, 79)       0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 1024, 79)     0           gru_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 72, 1024, 79) 0           softmax_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 72, 1024, 79) 0           permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 72, 1024, 79) 0           lambda_8[0][0]                   \n",
            "                                                                 lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 72, 1024)     0           multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 72, 2048)     0           lambda_10[0][0]                  \n",
            "                                                                 gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 72, 1024)     2098176     concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 72, 810)      830250      time_distributed_6[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 15,393,579\n",
            "Trainable params: 15,393,579\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5e80611db37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3k3BHz8quJa",
        "colab_type": "code",
        "outputId": "b54492e9-44cd-4b5e-d8e0-331d9fed582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "choice = input(\"Train?\") \n",
        "if choice == 'y' or choice == 'Y': \n",
        "    # 학습 \n",
        "    history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
        "                        batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=0, callbacks=[early_stopping]) \n",
        "    model.save_weights('att_seq2seq_weights.h5') \n",
        "    \n",
        "    # 손실 그래프 \n",
        "    plt.plot(history.history['loss'], 'y', label='train loss') \n",
        "    plt.plot(history.history['val_loss'], 'r', label='val loss') \n",
        "    plt.legend(loc='upper left') \n",
        "    plt.show() \n",
        "    \n",
        "    # 정확도 그래프 \n",
        "    plt.plot(history.history['acc'], 'y', label='train acc') \n",
        "    plt.plot(history.history['val_acc'], 'r', label='val acc') \n",
        "    plt.legend(loc='upper left') \n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train?y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PpoekJUlCGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    \n",
        "# 어텐션 검증 \n",
        "test_data_num = 0 \n",
        "test_max_len = 0 \n",
        "for i, s in enumerate(input_texts): \n",
        "    if len(s) > test_max_len: \n",
        "        test_max_len = len(s) \n",
        "        test_data_num = i \n",
        "        \n",
        "test_enc_input = encoder_input_data[test_data_num].reshape( (1, max_encoder_seq_length, num_encoder_tokens)) \n",
        "test_dec_input = decoder_input_data[test_data_num].reshape( (1, max_decoder_seq_length, num_decoder_tokens)) \n",
        "\n",
        "attention_layer = softmax_score_layer \n",
        "func = K.function([encoder_inputs, decoder_inputs] + [K.learning_phase()], [attention_layer.output]) \n",
        "score_values = func([test_enc_input, test_dec_input, 1.0])[0] \n",
        "score_values = score_values.reshape((max_decoder_seq_length, max_encoder_seq_length)) \n",
        "\n",
        "score_values = score_values[:len(target_texts[test_data_num])-1, :len(input_texts[test_data_num])] \n",
        "\n",
        "fig = plt.figure() \n",
        "ax = fig.add_subplot(111) \n",
        "cax = ax.matshow(score_values, interpolation='nearest') \n",
        "fig.colorbar(cax) \n",
        "\n",
        "test_enc_names = [] \n",
        "for vec in test_enc_input[0]: \n",
        "    sampled_token_index = np.argmax(vec) \n",
        "    sampled_char = reverse_input_char_index[sampled_token_index] \n",
        "    test_enc_names.append(sampled_char) \n",
        "test_dec_names = [] \n",
        "for vec in test_dec_input[0]: \n",
        "    sampled_token_index = np.argmax(vec) \n",
        "    sampled_char = reverse_target_char_index[sampled_token_index] \n",
        "    test_dec_names.append(sampled_char) \n",
        "    \n",
        "print(test_dec_names[1:len(target_texts[test_data_num])]) \n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) \n",
        "ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) \n",
        "ax.set_yticklabels(['']+test_dec_names[1:-1] + ['<END>'])\n",
        "ax.set_xticklabels(['']+test_enc_names)\n",
        "\n",
        "plt.show() \n",
        "\n",
        "# 추론(테스트) \n",
        "# 추론 모델 생성 \n",
        "encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h]) \n",
        "encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim)) \n",
        "\n",
        "decoder_inputs = layers.Input(shape=(1, num_decoder_tokens)) \n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,)) \n",
        "decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h) \n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2) \n",
        "repeat_d = repeat_d_layer(decoder_outputs) \n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1) \n",
        "repeat_e = repeat_e_layer(encoder_outputs_input) \n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1) \n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e]) \n",
        "\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer) \n",
        "dense1_score = dense1_score_layer(concat_for_score) \n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer) \n",
        "dense2_score = dense2_score_layer(dense1_score) \n",
        "dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score) \n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1) \n",
        "softmax_score = softmax_score_layer(dense2_score) \n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2) \n",
        "repeat_score = repeat_score_layer(softmax_score) \n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1) \n",
        "repeat_e = repeat_e_layer(permute_e) \n",
        "\n",
        "attended_mat_layer = layers.Multiply() \n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e]) \n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1), \n",
        "                              lambda x: tuple(x[:-1])) \n",
        "context = context_layer(attended_mat) \n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1) \n",
        "concat_context = concat_context_layer([context, decoder_outputs]) \n",
        "\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer) \n",
        "attention_output = attention_output_layer(concat_context) \n",
        "\n",
        "decoder_att_outputs = decoder_dense(attention_output) \n",
        "\n",
        "decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input], [decoder_outputs, decoder_h, decoder_att_outputs]) \n",
        "#decoder_model.summary() \n",
        "#plot_model(decoder_model, show_shapes=True, to_file='decoder_model.png') \n",
        "#display(Image(filename='decoder_model.png')) \n",
        "\n",
        "def decode_sequence(input_seq): \n",
        "    # 입력 문장을 인코딩 \n",
        "    enc_outputs, states_value = encoder_model.predict(input_seq) \n",
        "    # 디코더의 입력으로 쓸 단일 문자 \n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens)) \n",
        "    # 첫 입력은 시작 문자인 '\\t'로 설정 \n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1. \n",
        "    \n",
        "    # 문장 생성 \n",
        "    stop_condition = False \n",
        "    decoded_sentence = '' \n",
        "    while not stop_condition: \n",
        "        # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음 \n",
        "        # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨. \n",
        "        dec_outputs, h, output_tokens = decoder_model.predict( \n",
        "            [target_seq, states_value, enc_outputs]) \n",
        "        \n",
        "        # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환 \n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) \n",
        "        sampled_char = reverse_target_char_index[sampled_token_index] \n",
        "        decoded_sentence += sampled_char \n",
        "        \n",
        "        # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료 \n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length): \n",
        "            stop_condition = True \n",
        "            \n",
        "        # 디코더의 다음 입력으로 쓸 데이터 갱신 \n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens)) \n",
        "        target_seq[0, 0, sampled_token_index] = 1. \n",
        "        \n",
        "        states_value = h \n",
        "        \n",
        "    return decoded_sentence \n",
        "    \n",
        "for seq_index in range(30): \n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1] \n",
        "    decoded_sentence = decode_sequence(input_seq) \n",
        "    print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msiUXb-hJOg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            temp = temp + src_index_to_word[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
        "            temp = temp + tar_index_to_word[i] + ' '\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xvCHPlmJQgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트 샘플 중 500번부터 1000번까지 테스트해봅시다.\n",
        "for i in range(1, 100):\n",
        "    print(\"원문 : \",seq2text(X_test[i]))\n",
        "    print(\"실제 요약문 :\",seq2summary(y_test[i]))\n",
        "    print(\"예측 요약문 :\",decode_sequence(X_test[i].reshape(1, ori_max_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}