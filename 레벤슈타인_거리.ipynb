{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "레벤슈타인 거리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFgX+JwT8/hUFPvMvhOyqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moey920/NLP/blob/master/%EB%A0%88%EB%B2%A4%EC%8A%88%ED%83%80%EC%9D%B8_%EA%B1%B0%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrSE7VwrR8UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install soynlp\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import re\n",
        "import sys\n",
        "from os import listdir\n",
        "from os.path import isfile, join, basename\n",
        "\n",
        "from soynlp.hangle import levenshtein\n",
        "from soynlp.hangle import jamo_levenshtein\n",
        "\n",
        "from konlpy.tag import Kkma, Okt\n",
        "from konlpy.utils import pprint\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def edit_distance(s1, s2):\n",
        "    s1 = re.split(' |\\n|\\t', s1)\n",
        "    s1 = filter(None, s1)\n",
        "    s2 = re.split(' |\\n|\\t', s2)\n",
        "    s2 = filter(None, s2)\n",
        "    s1 = ' '.join(s1)\n",
        "    s2 = ' '.join(s2)\n",
        "    #    print s1\n",
        "    #    print s2\n",
        "    l1 = len(s1)\n",
        "    l2 = len(s2)\n",
        "    if l2 == 0:\n",
        "        return l1\n",
        "    # previous_row = xrange(l2 + 1)\n",
        "    previous_row = range(l2 + 1)\n",
        "    for i, c1 in enumerate(s1):\n",
        "        current_row = [i + 1]\n",
        "        flag = 0\n",
        "        for j, c2 in enumerate(s2):\n",
        "            insertions = previous_row[\n",
        "                             j + 1] + 1  # j+1 instead of j since previous_row and current_row are one character longer\n",
        "            deletions = current_row[j] + 1  # than s2\n",
        "            substitutions = previous_row[j] + (c1 != c2)\n",
        "            current_row.append(min(insertions, deletions, substitutions))\n",
        "        previous_row = current_row\n",
        "    return (float(previous_row[-1]), float(l2))\n",
        "\n",
        "\n",
        "def ocr_ans(user, ground):\n",
        "    kkma = Kkma()\n",
        "    okt = Okt()\n",
        "\n",
        "    userfiles = [f for f in listdir(user) if isfile(join(user, f))]\n",
        "    userfiles.sort()\n",
        "    groundfiles = [f for f in listdir(ground) if isfile(join(ground, f))]\n",
        "    s = 0.0\n",
        "    count = 0\n",
        "    outputfile = open('output.txt', 'w+')\n",
        "\n",
        "    for f in userfiles:\n",
        "        # mydoclist_kkma = []\n",
        "        # okt_ground = []\n",
        "        # okt_user = []\n",
        "\n",
        "        f2 = (f.split('_'))[:-1]\n",
        "        # f2 = (f.split('_'))[:1]\n",
        "        # f2 = basename(f)\n",
        "        # f2 = f\n",
        "        # filename = ground + '/' + '_'.join(f2) + '.txt'\n",
        "        if len(f2) == 0:\n",
        "            f2 = f.split('.')[:-1]\n",
        "        if len(f2) == 0:\n",
        "            # print(\"debug ----- can not get user file name body >> continue\")\n",
        "            continue\n",
        "        # ground_filename = join(ground, '_'.join(f2) + '_hand.txt')\n",
        "        ground_filename = join(ground, f2[0] + '_hand.txt')\n",
        "        '''\n",
        "        filenames = []\n",
        "        filenames.append(join(ground, '_'.join(f2) + '.txt'))\n",
        "        filenames.append(join(ground, '_'.join(f2) + '_masked.txt'))\n",
        "        filenames.append(join(ground, '_'.join(f2) + '_box_transform.txt'))\n",
        "        filenames.append(join(ground, '_'.join(f2) + '_vs_transform.txt'))\n",
        "        '''\n",
        "        # print 'user : ', user + '/' + f\n",
        "        # print(\"user:\", user + '/' + f)\n",
        "        # userfile = open(user + '/' + f, 'r')\n",
        "        # userfile = open(join(user, f), 'rt', encoding='utf-8')\n",
        "        user_filename = join(user, f)\n",
        "        try:\n",
        "            with open(user_filename, 'rt', encoding='utf-8') as userfile:\n",
        "                # print(\"user file:\", user_filename)\n",
        "                user_text = userfile.read()\n",
        "        except IOError as exc:\n",
        "            '''\n",
        "            tb = sys.exc_info()[-1]\n",
        "            lineno = tb.tb_lineno\n",
        "            src = tb.tb_frame.f_code.co_filename\n",
        "            print('{} at {} line {}.'.format(exc.strerror, src, lineno))\n",
        "            '''\n",
        "            continue\n",
        "        '''\n",
        "        try:\n",
        "            user_text = user_text.decode('utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            try:\n",
        "                user_text = user_text.decode('utf-16')\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "        '''\n",
        "        # print \"ground : \", filename\n",
        "        try:\n",
        "            with open(ground_filename, 'rt', encoding='utf-8') as groundfile:\n",
        "                # print(\"ground file:\", ground_filename)\n",
        "                ground_text = groundfile.read()\n",
        "            '''\n",
        "            try:\n",
        "                ground_text = ground_text.decode('utf-8')\n",
        "            except UnicodeDecodeError:\n",
        "                try:\n",
        "                    ground_text = ground_text.decode('utf-16')\n",
        "                except UnicodeDecodeError:\n",
        "                    continue\n",
        "            '''\n",
        "        except IOError as exc:\n",
        "            '''\n",
        "            tb = sys.exc_info()[-1]\n",
        "            lineno = tb.tb_lineno\n",
        "            src = tb.tb_frame.f_code.co_filename\n",
        "            print('{} at {} line {}.'.format(exc.strerror, src, lineno))\n",
        "            '''\n",
        "            continue\n",
        "\n",
        "        # 자기 자신을 넣어보면 e[0]/e[1]은 0.0이 나온다.\n",
        "        # e = edit_distance(ground_text, ground_text)\n",
        "        # print(\"debug ---- dist ground_text/ground_text\", e[0]/e[1])\n",
        "        e = edit_distance(user_text, ground_text)\n",
        "        # print(count, basename(user_filename), basename(ground_filename), e[0] / e[1])\n",
        "\n",
        "        # soynlp 루벤스타인+자모 루벤스타인 조사\n",
        "        l = levenshtein(user_text, ground_text)\n",
        "        jl = jamo_levenshtein(user_text, ground_text)\n",
        "\n",
        "        # konlpy 를 사용해서 명사만 구하고 이를 다시 soynlp 루벤스타인+자모 루벤스타인 조사\n",
        "        okt_user_nouns = ' '.join(okt.nouns(user_text))\n",
        "        okt_ground_nouns = ' '.join(okt.nouns(ground_text))\n",
        "        # okt_user.append(okt_user_nouns)\n",
        "        # okt_ground.append(okt_ground_nouns)\n",
        "        lo = levenshtein(okt_user_nouns, okt_ground_nouns)\n",
        "        jlo = jamo_levenshtein(okt_user_nouns, okt_ground_nouns)\n",
        "\n",
        "        outputstring = (\n",
        "                str(count) + '\\t' +\n",
        "                basename(user_filename) + '\\t' + basename(ground_filename) + '\\t' +\n",
        "                str(float(e[0]) / float(e[1]) * 100) + '\\t' +\n",
        "                str(l) + '\\t' + str(jl) + '\\t' +\n",
        "                str(lo) + '\\t' + str(jlo)\n",
        "        )\n",
        "        print(outputstring)\n",
        "        outputfile.write(outputstring+'\\n')\n",
        "        count += 1\n",
        "        '''\n",
        "        s += e[0] / e[1]\n",
        "        outputstring = '_'.join(f2) + '\\t' + str(e[1]) + '\\t' + str(e[0]) + '\\t' + str(\n",
        "            float(e[0]) / float(e[1]) * 100) + '\\n'\n",
        "        outputfile.write(outputstring)\n",
        "        count += 1\n",
        "        print(s, count)\n",
        "        print(s / float(count))\n",
        "        '''\n",
        "\n",
        "ocr_ans(sys.argv[1], sys.argv[2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}