{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer (Attention Is All You Need) 구현하기",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1kNN3ylKBj6Sad5sUahBcQa1AVknu5i7t",
      "authorship_tag": "ABX9TyMvIh6C69oYVZj0PlwHlh66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moey920/NLP/blob/master/Transformer_(Attention_Is_All_You_Need)_%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Yjg5okkqZXf",
        "colab_type": "text"
      },
      "source": [
        "이 포스트는 Transformer 모델 구현에 대한 설명 입니다. 논문에 대한 내용은 Attention Is All You Need 논문을 참고 하거나 다른 블로그를 참고 하세요.\n",
        "\n",
        "https://arxiv.org/abs/1706.03762\n",
        "\n",
        "미리 확인해야할 포스트\n",
        "- Sentencepiece를 활용해 Vocab 만들기(https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- Naver 영화리뷰 감정분석 데이터 전처리 하기(https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- Transformer (Attention Is All You Need) 구현하기 (1/3)(https://paul-hyun.github.io/transformer-01/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiF6jmhstf3a",
        "colab_type": "text"
      },
      "source": [
        "# 선행작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w8RCV_wtkxd",
        "colab_type": "text"
      },
      "source": [
        "## 0. Pip Install\n",
        "\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPexn2PtpdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMCkP7Yft5sG",
        "colab_type": "text"
      },
      "source": [
        "## 0-1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "\n",
        "아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkpS_auuDWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/캐시카우_노하람인턴_공유폴더/transformer\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7KWuwtlvyXU",
        "colab_type": "text"
      },
      "source": [
        "## 0-2 Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqV-xvZ-v2Wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20U62dyjv4zl",
        "colab_type": "text"
      },
      "source": [
        "## 0-3. 폴더의 목록을 확인\n",
        "\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7vlYsYmv9I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVxT32mlv_x-",
        "colab_type": "text"
      },
      "source": [
        "## 0-4 Vocab 및 입력\n",
        "\n",
        "Sentencepiece를 활용해(https://paul-hyun.github.io/vocab-with-sentencepiece/) Vocab 만들기를 통해 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPL5ZUuqwKkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab loading.\n",
        "vocab_file = f\"/content/drive/My Drive/캐시카우_노하람인턴_공유폴더/transformer/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVwT0N75qBvx",
        "colab_type": "text"
      },
      "source": [
        "# 1. Config\n",
        "\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다.\n",
        "\n",
        "Transformer 모델에는 많은 설정이 필요합니다. 이 설정을 json 형태로 저장을 하고 이를 읽어서 처리하는 간단한 클래스 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEZlAsfxp-OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feflG_DOqN0m",
        "colab_type": "text"
      },
      "source": [
        "작은 리소스에서도 동작 가능하도록 여러 파라미터를 작게 설정 했습니다. 가지고 계신 GPU가 여유가 있다면 파라미터를 키우면 더 좋은 결과를 확인 할 수 있을 겁니다. 기본 파라미터는 config.json을 참고 하세요.\n",
        "\n",
        "https://github.com/paul-hyun/transformer-evolution/blob/master/transformer/config.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qbLLiL8qLSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQj2Gu2qsbo",
        "colab_type": "text"
      },
      "source": [
        "아래와 같은 파라미터 정보를 확인 할 수 있습니다.\n",
        "\n",
        "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_TDl8Z0qxEL",
        "colab_type": "text"
      },
      "source": [
        "# 2. Common Class\n",
        "\n",
        "공통으로 사용되는 Class 및 함수 입니다.\n",
        "\n",
        "Transformer (Attention Is All You Need) 구현하기 (1/3)에서 설명한 ‘Position Embedding’, ‘Multi-Head Attention’, ‘Feeed Forward’등의 코드 입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KugXGdPWrcU7",
        "colab_type": "text"
      },
      "source": [
        "### get_sinusoid_encoding_table\n",
        "\n",
        "Position Embedding의 초기 값을 구하는 함수 입니다.\n",
        "\n",
        "- Positional Encoding 값을 구하기 위한 함수 입니다.\n",
        "\n",
        "1. 각 position별 hidden index별 angle값을 구합니다. (줄: 8)\n",
        "2. hidden 짝수 index의 angel값의 sin값을 합니다. (줄: 9)\n",
        "3. hidden 홀수 index의 angel값의 cos값을 합니다. (줄: 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFqyBMiXqUPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYM4ERY-q8LH",
        "colab_type": "text"
      },
      "source": [
        "### get_attn_pad_mask\n",
        "\n",
        "Attention을 구할 때 Padding 부분을 제외하기 위한 Mask를 구하는 함수 입니다.\n",
        "\n",
        "1. K의 값 중에 Pad인 부분을 True로 변경 합니다. (나머지는 False) (줄: 5)\n",
        "2. 구해진 값의 크기를 Q-len, K-len 되도록 변경 합니다. (줄: 6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4k3OUESq-JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad)\n",
        "    pad_attn_mask= pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return pad_attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_EsCtpDq_qo",
        "colab_type": "text"
      },
      "source": [
        "### get_attn_decoder_mask\n",
        "- Decoder의 ‘Masked Multi Head Attention’에서 사용할 Mask를 구하는 함수 입니다. (Decoder Mask를 구하기 위한 함수 입니다.)\n",
        "\n",
        "현재단어와 이전단어는 볼 수 있고 다음단어는 볼 수 없도록 Masking 합니다.\n",
        "\n",
        "1. 모든 값이 1인 Q-len, K-len 테이블을 생성 합니다. (줄: 3)\n",
        "2. 대각선을 기준으로 아래쪽을 0으로 만듭니다. (줄: 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYe_OPpsrEcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PhcV-iRrIXb",
        "colab_type": "text"
      },
      "source": [
        "### Scaled Dot Product Attention을 구하는 클래스 입니다.\n",
        "\n",
        "1. Q * K.transpose를 구합니다. (줄: 11)\n",
        "2. K-dimension에 루트를 취한 값으로 나줘 줍니다. (줄: 12)\n",
        "3. Mask를 적용 합니다. (줄: 13)\n",
        "4. Softmax를 취해 각 단어의 가중치 확률분포 attn_prob를 구합니다. (줄: 15)\n",
        "5. attn_prob * V를 구합니다. 구한 값은 Q에 대한 V의 가중치 합 벡터입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRGehCMfrMlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2))\n",
        "        scores = scores.mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl86SsDFrOZG",
        "colab_type": "text"
      },
      "source": [
        "### Multi-Head Attention을 구하는 클래스 입니다.\n",
        "\n",
        "1. Q * W_Q를 한 후 multi-head로 나눕니다. (줄: 17)\n",
        "2. K * W_K를 한 후 multi-head로 나눕니다. (줄: 19)\n",
        "3. V * W_V를 한 후 multi-head로 나눕니다. (줄: 21)\n",
        "4. ScaledDotProductAttention 클래스를 이용해 각 head별 Attention을 구합니다 (줄: 27)\n",
        "5. 여러 개의 head를 1개로 합칩니다. (줄: 29)\n",
        "6. Linear를 취해 최종 Multi-Head Attention값을 구합니다. (줄: 31)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-lTXEoNrTwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpfWUfdXrVRv",
        "colab_type": "text"
      },
      "source": [
        "### FeeedForward를 처리하는 클래스 입니다.\n",
        "\n",
        "1. Linear를 실행하여 shape을 d_ff(hidden * 4) 크기로 키웁니다. (줄: 14)\n",
        "2. activation 함수(relu or gelu)를 실행합니다. (줄: 15)\n",
        "3. Linear를 실행하여 shape을 hidden 크기로 줄입니다. (줄: 17)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okBiEjm4rmbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.conv1(inputs.transpose(1, 2))\n",
        "        output = self.active(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgy9VYdcroFg",
        "colab_type": "text"
      },
      "source": [
        "# 3. Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Uq0wxYrryT",
        "colab_type": "text"
      },
      "source": [
        "### Encoder Layer\n",
        "\n",
        "Encoder에서 루프를 돌며 처리 할 수 있도록 EncoderLayer를 정의하고 여러 개 만들어서 실행 합니다.\n",
        "\n",
        "1. Multi-Head Attention을 수행합니다. (줄: 14)\n",
        "\n",
        " Q, K, V 모두 동일한 값을 사용하는 self-attention 입니다.\n",
        "2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행 합니다. (줄: 15)\n",
        "3. 2번의 결과를 입력으로 Feed Forward를 실행 합니다. (줄: 17)\n",
        "4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행 합니다. (줄: 18)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTroraoYrpie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiJffWw5r2Rq",
        "colab_type": "text"
      },
      "source": [
        "### Encoder 클래스 입니다.\n",
        "\n",
        "1. 입력에 대한 Position 값을 구합니다. (줄: 14~16)\n",
        "2. Input Embedding과 Position Embedding을 구한 후 더합니다. (줄: 19)\n",
        "3. 입력에 대한 attention pad mask를 구합니다. (줄: 22)\n",
        "4. for 루프를 돌며 각 layer를 실행합니다. (줄: 27)\n",
        "5. layer의 입력은 이전 layer의 출력 값 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaKUu2dPr7ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEQJKv2JsBN3",
        "colab_type": "text"
      },
      "source": [
        "# 4. Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JjUt56usFS_",
        "colab_type": "text"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "Decoder에서 루프를 돌며 처리 할 수 있도록 DecoderLayer를 정의하고 여러 개 만들어서 실행 합니다.\n",
        "\n",
        "1. Multi-Head Attention을 수행합니다. (줄: 16)\n",
        "\n",
        "    Q, K, V 모두 동일한 값을 사용하는 self-attention 입니다.\n",
        "2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행 합니다. (줄: 17)\n",
        "3. Encoder-Decoder Multi-Head Attention을 수행합니다. (줄: 19)\n",
        "    \n",
        "    Q: 2번의 결과\n",
        "    \n",
        "    K, V: Encoder 결과\n",
        "4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행 합니다. (줄: 20)\n",
        "5. 4번의 결과를 입력으로 Feed Forward를 실행 합니다. (줄: 22)\n",
        "6. 5번의 결과와 4번의 결과(residual)을 더한 후 LayerNorm을 실행 합니다. (줄: 23)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8X3Bs4RsCmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrcQfxqasSqt",
        "colab_type": "text"
      },
      "source": [
        "### Decoder 클래스 입니다.\n",
        "\n",
        "1. 입력에 대한 Position 값을 구합니다. (줄: 14~16)\n",
        "2. Input Embedding과 Position Embedding을 구한 후 더합니다. (줄: 19)\n",
        "3. 입력에 대한 attention pad mask를 구합니다. (줄: 22)\n",
        "4. 입력에 대한 decoder attention mask를 구합니다. (줄: 24)\n",
        "5. attention pad mask와 decoder attention mask 중 1곳이라도 mask되어 있는 부분인 mask 되도록 attention mask를 구합니다. (줄: 26)\n",
        "6. Q(decoder input), K(encoder output)에 대한 attention mask를 구합니다. (줄: 28)\n",
        "7. for 루프를 돌며 각 layer를 실행합니다. (줄: 27)\n",
        "    \n",
        "    layer의 입력은 이전 layer의 출력 값 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JFo8zlKsZ62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "        # (bs, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
        "\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RDTDwF_sdK0",
        "colab_type": "text"
      },
      "source": [
        "# 5. Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CWXgUrPsgVk",
        "colab_type": "text"
      },
      "source": [
        "### Transformer 클래스 입니다.\n",
        "\n",
        "1. Encoder Input을 입력으로 Encoder를 실행합니다. (줄: 12)\n",
        "2. Encoder Output과 Decoder Input을 입력으로 Decoder를 실행합니다. (줄: 14)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD5eCskVsja9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" transformer \"\"\"\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KGJgVO2iaam",
        "colab_type": "text"
      },
      "source": [
        "# 6. Transformer 클래스를 이용하여 모델 정의\n",
        "영수증 번역 모델 모델 클래스를 아래와 같이 정의합니다.\n",
        "\n",
        "1. Encoder input과 Decoder input을 입력으로 Transformer 모델을 실행 합니다. (줄: 12)\n",
        "2. Transformer 출력의 max값을 구합니다. (줄: 14)\n",
        "3. Linear를 실행하여 최종 예측 결과를 만듭니다. (줄: 16)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTbfksQ3iX_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = Transformer(self.config)\n",
        "        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "        #self.projection = nn.Softmax(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n",
        "        # (bs, d_hidn)\n",
        "        #dec_outputs, _ = torch.max(dec_outputs, dim=1)\n",
        "        dec_outputs, _ = torch.max(dec_outputs)\n",
        "        # (bs, n_output)\n",
        "        logits = self.projection(dec_outputs)\n",
        "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1g4-QJEieE1",
        "colab_type": "text"
      },
      "source": [
        "# 7. Dataset\n",
        "영수증 데이터셋을 불러옵니다.\n",
        "\n",
        "1. 입력 파일로 부터 ‘label’을 읽어 들입니다. (줄: 16)\n",
        "2. 입력 파일로 부터 ‘doc’ token을 읽어 숫자(token id)로 변경 합니다. (줄: 17)\n",
        "3. Decoder 입력은 ‘[BOS]’로 고정 합니다. (줄: 26)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UCfYDLAie0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 영수증 번역 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item): #라벨값 오류발생.\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cam4pOZCj3jQ",
        "colab_type": "text"
      },
      "source": [
        "### collate_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ESgA5fHj6cR",
        "colab_type": "text"
      },
      "source": [
        "배치단위로 데이터 처리를 위한 collate_fn 입니다.\n",
        "\n",
        "1. Encoder inputs의 길이가 같아지도록 짧은 문장에 padding(0)을 추가 합니다. (줄: 5)\n",
        "    \n",
        "    padding은 Sentencepiece를 활용해 Vocab 만들기에서 ‘–pad_id=0’옵션으로 지정한 값 입니다.\n",
        "2. Decoder inputs의 길이가 같아지도록 짧은 문장에 padding(0)을 추가 합니다. (줄: 6)\n",
        "3. Label은 길이가 1 고정이므로 stack 함수를 이용해 tensor로 만듭니다. (줄: 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VjZMkuLihfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=0)\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        #torch.stack(labels, dim=0),\n",
        "        labels,\n",
        "        enc_inputs,\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhKfYPV4kBiI",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llNWxubvkH_z",
        "colab_type": "text"
      },
      "source": [
        "위에서 정의한 DataSet과 collate_fn을 이용해 학습용(train_loader), 평가용(test_loader) DataLoader를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-joklKeincm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6isgDEmHiycJ",
        "colab_type": "text"
      },
      "source": [
        "# 8. Evaluate(평가) 함수\n",
        "학습된 MovieClassification 모델의 성능을 평가하기 위한 함수 입니다. 평가는 정확도(accuracy)를 사용 했습니다.\n",
        "\n",
        "1. Encoder input과 Decoder input을 입력으로 MovieClassification을 실행합니다. (줄: 12)\n",
        "2. 1번의 결과 중 첫 번째 값이 예측 logits 입니다. (줄: 13)\n",
        "3. logits의 최대값의 index를 구합니다. (줄: 14)\n",
        "4. 3번에게 구한 값과 labels의 값이 같은지 비교 합니다. (줄: 16)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tawwd9J2izTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "            _, indices = logits.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btdH3zzRkY1P",
        "colab_type": "text"
      },
      "source": [
        "# 9. Train(학습) 함수\n",
        "\n",
        "MovieClassification 모델을 학습하기 위한 함수 입니다.\n",
        "\n",
        "1. Encoder input과 Decoder input을 입력으로 MovieClassification을 실행합니다. (줄: 11)\n",
        "2. 1번의 결과 중 첫 번째 값이 예측 logits 입니다. (줄: 12)\n",
        "3. logits 값과 labels의 값을 이용해 Loss를 계산합니다. (줄: 14)\n",
        "4. loss, optimizer를 이용해 학습합니다. (줄: 18, 19)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2LEmPIEi02x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            loss_val = loss.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZqrImDhkhdI",
        "colab_type": "text"
      },
      "source": [
        "학습을 위한 추가적인 내용을 선언 합니다.\n",
        "\n",
        "1. GPU 사용 여부를 확인합니다. (줄: 1)\n",
        "3. learning_rate 및 학습 epoch를 선언 합니다. (줄: 5, 6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLz8vwuGi3Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwSCf9-pkwxW",
        "colab_type": "text"
      },
      "source": [
        "# 10. 학습 실행\n",
        "위에서 선언된 내용을 이용해 학습을 실행하는 절차 입니다.\n",
        "\n",
        "1. MovieClassification을 생성합니다. (줄: 1)\n",
        "2. MovieClassification이 GPU 또는 CPU를 지원하도록 합니다. (줄: 2)\n",
        "3. loss 함수를 선언 합니다. (줄: 4)\n",
        "4. optimizer를 선언 합니다. (줄: 5)\n",
        "5. 각 epoch 마다 학습을 합니다. (줄: 9)\n",
        "6. 각 epoch 마다 평가를 합니다. (줄: 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqwQsQGVi5Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_epoch, best_loss, best_score = 0, 0, 0\n",
        "losses, scores = [], []\n",
        "for epoch in range(n_epoch):\n",
        "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
        "    score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "    losses.append(loss)\n",
        "    scores.append(score)\n",
        "\n",
        "    if best_score < score:\n",
        "        best_epoch, best_loss, best_score = epoch, loss, score\n",
        "print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LqddruRk3uY",
        "colab_type": "text"
      },
      "source": [
        "# 11. Result\n",
        "학습결과 및 평가결과는 아래와 같습니다.\n",
        "정확도(score)가 83.5% 정도 나왔습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLIh1XC9i7M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {\n",
        "    \"loss\": losses,\n",
        "    \"score\": scores\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.plot(scores, label=\"score\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}